{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dell\\miniconda3\\envs\\gyenv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import pennylane as qml\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.parameter import Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self,\n",
    "                 net,\n",
    "                 action_space=None,\n",
    "                 exploration_initial_eps=None,\n",
    "                 exploration_decay=None,\n",
    "                 exploration_final_eps=None):\n",
    "\n",
    "        self.net = net\n",
    "        self.action_space = action_space\n",
    "        self.exploration_initial_eps = exploration_initial_eps\n",
    "        self.exploration_decay = exploration_decay\n",
    "        self.exploration_final_eps = exploration_final_eps\n",
    "        self.epsilon = 0.\n",
    "\n",
    "    def __call__(self, state, device=torch.device('cpu')):\n",
    "        if np.random.random() < self.epsilon:\n",
    "            action = self.get_random_action()\n",
    "        else:\n",
    "            action = self.get_action(state, device)\n",
    "\n",
    "        return action\n",
    "\n",
    "    def get_random_action(self):\n",
    "        action = self.action_space.sample()\n",
    "        return action\n",
    "\n",
    "    def get_action(self, state, device=torch.device('cpu')):\n",
    "        if not isinstance(state, torch.Tensor):\n",
    "            state = torch.tensor(np.array([state]))\n",
    "\n",
    "        if device.type != 'cpu':\n",
    "            state = state.cuda(device)\n",
    "\n",
    "        q_values = self.net.eval()(state)\n",
    "        _, action = torch.max(q_values, dim=1)\n",
    "        return int(action.item())\n",
    "\n",
    "    def update_epsilon(self, step):\n",
    "        self.epsilon = max(\n",
    "            self.exploration_final_eps, self.exploration_final_eps +\n",
    "            (self.exploration_initial_eps - self.exploration_final_eps) *\n",
    "            self.exploration_decay**step)\n",
    "        return self.epsilon\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_agent(env, agent, n_eval_episodes):\n",
    "    episode_steps = []\n",
    "    episode_reward = []\n",
    "\n",
    "    for _ in range(n_eval_episodes):\n",
    "        state,_ = env.reset()\n",
    "        done = False\n",
    "        episode_steps.append(0)\n",
    "        episode_reward.append(0)\n",
    "        for i in range(100):\n",
    "            action = agent.get_action(state)\n",
    "            next_state, reward, terminated, truncated ,_= env.step(action)\n",
    "            done = terminated or truncated\n",
    "            #state = next_state\n",
    "            episode_steps[-1] += 1\n",
    "            episode_reward[-1] += reward\n",
    "            if done:\n",
    "                break\n",
    "            else:\n",
    "                state = next_state\n",
    "\n",
    "    episode_steps = np.mean(episode_steps)\n",
    "    episode_reward = np.mean(episode_reward)\n",
    "    return {'steps': episode_steps, 'reward': episode_reward}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "\n",
    "Transition = namedtuple('Transition',\n",
    "                        ('state', 'action', 'reward', 'done', 'next_state'))\n",
    "\n",
    "\n",
    "class ReplayMemory(object):\n",
    "    def __init__(self, buffer_size):\n",
    "        self.buffer_size = buffer_size\n",
    "        self.memory = []\n",
    "        self.position = 0\n",
    "\n",
    "    def push(self, *args):\n",
    "        if len(self.memory) < self.buffer_size:\n",
    "            self.memory.append(None)\n",
    "        self.memory[self.position] = Transition(*args)\n",
    "        self.position = (self.position + 1) % self.buffer_size\n",
    "\n",
    "    def sample(self, batch_size, device):\n",
    "        indices = np.random.choice(len(self), batch_size, replace=False)\n",
    "        states, actions, rewards, dones, next_states = zip(\n",
    "            *[self.memory[idx] for idx in indices])\n",
    "        states = torch.from_numpy(np.array(states)).to(device)\n",
    "        actions = torch.from_numpy(np.array(actions)).to(device)\n",
    "        rewards = torch.from_numpy(np.array(rewards,\n",
    "                                            dtype=np.float32)).to(device)\n",
    "        dones = torch.from_numpy(np.array(dones, dtype=np.int32)).to(device)\n",
    "        next_states = torch.from_numpy(np.array(next_states)).to(device)\n",
    "        return states, actions, rewards, dones, next_states\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym.spaces\n",
    "\n",
    "class BinaryWrapper(gym.ObservationWrapper):\n",
    "    def __init__(self, env):\n",
    "        super(BinaryWrapper, self).__init__(env)\n",
    "        self.bits = int(np.ceil(np.log2(env.observation_space.n)))\n",
    "        self.observation_space = gym.spaces.MultiBinary(self.bits)\n",
    "\n",
    "    def observation(self, obs):\n",
    "        binary = map(float, \"{0:b}\".format(int(obs)).zfill(self.bits))\n",
    "        return np.array(list(binary))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"def encode(n_qubits, inputs):\n",
    "    for wire in range(n_qubits):\n",
    "        qml.RX(inputs[wire], wires=wire)\"\"\"\n",
    "\n",
    "\n",
    "\"\"\"def layer(n_qubits, y_weight, z_weight):\n",
    "    for wire, y_weight in enumerate(y_weight):\n",
    "        qml.RY(y_weight, wires=wire)\n",
    "    for wire, z_weight in enumerate(z_weight):\n",
    "        qml.RZ(z_weight, wires=wire)\n",
    "    for wire in range(n_qubits):\n",
    "        qml.CZ(wires=[wire, (wire + 1) % n_qubits])\n",
    "\n",
    "\n",
    "def measure(n_qubits):\n",
    "    return [qml.expval(qml.PauliZ(wire)) for wire in range(n_qubits)]\"\"\"\n",
    "\n",
    "\n",
    "def get_model(n_qubits, n_layers, data_reupload):\n",
    "    dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
    "    shapes = {\n",
    "        \"y_weights\": (n_layers, n_qubits),\n",
    "    }\n",
    "\n",
    "    @qml.qnode(dev, interface='torch')\n",
    "    def circuit(inputs, y_weights, z_weights):\n",
    "        for layer_idx in range(n_layers):\n",
    "            if (layer_idx == 0) or data_reupload:\n",
    "                for wire in range(n_qubits):\n",
    "                    qml.RX(inputs[wire], wires=wire)\n",
    "            for wire, y_weight in enumerate(y_weight):\n",
    "                qml.RY(y_weight, wires=wire)\n",
    "            for wire in range(n_qubits):\n",
    "                qml.CZ(wires=[wire, (wire + 1) % n_qubits])\n",
    "        return [qml.expval(qml.PauliZ(wire)) for wire in range(n_qubits)]\n",
    "\n",
    "    model = qml.qnn.TorchLayer(circuit, shapes)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "class QuantumNet(nn.Module):\n",
    "    def __init__(self, n_layers):\n",
    "        super(QuantumNet, self).__init__()\n",
    "        self.n_qubits = 4\n",
    "        self.n_actions = 4\n",
    "        self.q_layers = get_model(n_qubits=self.n_qubits,\n",
    "                                  n_layers=n_layers,\n",
    "                                  data_reupload=False)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        inputs = inputs * np.pi\n",
    "        outputs = self.q_layers(inputs)\n",
    "        outputs = (1 + outputs) / 2\n",
    "        return outputs\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gyenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
